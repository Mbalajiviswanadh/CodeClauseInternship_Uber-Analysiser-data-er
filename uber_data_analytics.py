# -*- coding: utf-8 -*-
"""Uber Data Analytics

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yhNCPhD1RW9W5os6i_Z9r8JF8y7Js42N

#Uber Data Analytics

##Load the necessary libraries.
"""

import pandas as pd
import numpy as np
import datetime
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
matplotlib.style.use('ggplot')
import calendar

"""##Import the dataset and Load the dataset."""

uber_data  = pd.read_csv ('/content/uberdrive.csv')

##Show the starting 10 records of the dataset.
uber_data.head(10)

"""##Show the last 10 records of the dataset."""

uber_data.tail(10)

"""##Dimension of the dataset."""

uber_data.shape

1156-507

"""##Size of the dataset."""

uber_data.size

"""##Information about all the variables of the data set."""

uber_data.info()

"""##Checking for missing values."""

if (True):
  print( uber_data.isnull().values.any(), '\n"Data set has null values"')
else :
  print(uber_data.isnull().values.any(), '\n"Data set has no null values"')

"""##No-of missing values"""

uber_data.isnull().values.sum()

uber_data.isnull().sum()

sns.heatmap(uber_data.isnull(), yticklabels=False, cmap = "viridis")

"""##Initial data (nameing it as 'df') with dropping the NA values."""

df =uber_data.dropna()
df.isnull().values.any()
#After Dropping the NA values
sns.heatmap(df.isnull(),yticklabels=False, cmap="viridis")

df.shape

"""##The summary of the original data (before dropping the 'NA' values)."""

uber_data.describe()

"""##The information of the new dataframe. (df)"""

df.describe()

uber_data.head(2)

"""##The unique **start** destinations.
###dataframe with 'na' values in the 'START' variable.
"""

len(uber_data["START*"].unique())

a = set(uber_data["START*"])
len(a)

un_start_destination = uber_data["START*"].dropna()
unique_start = set(un_start_destination)
unique_start

"""##Total number of unique start destinations
###dataframe with no 'na' values in the 'START' variable.
"""

len(unique_start)

"""##Total number of unique **stop** destinations.
###dataframe with no 'na' values in the 'STOP' variable.
"""

b = set(uber_data["STOP*"])
len(b)

stop_destination = uber_data["STOP*"].dropna()
unique_stop = set(stop_destination)
len(unique_stop)

"""##Uber trips that has the starting point of San Francisco
###dataframe without dropping the 'na' values.
"""

uber_data[uber_data['START*']=='San Francisco']
#OR
#uber_data.loc[uber_data["START*"] == "San Francisco"]

len(uber_data[uber_data['START*']=='San Francisco'])

uber_data[uber_data['STOP*'].isin(['Katy','Berkeley'])]

#Central,Austin,San Francisco
uber_data[uber_data['START*'].isin(['San Francisco','Central','Austin'])]

uber_data[uber_data['STOP*'].isin(['Katy','Berkeley']) | uber_data['START*'].isin(['San Francisco','Central','Austin'])]

"""##The **most popular starting point for the Uber drivers
###dataframe with no 'na' values in the 'START' variable.
"""

starting_point = uber_data["START*"].dropna()
starting_point

df = pd.DataFrame(starting_point.value_counts())
df

df.sort_values(["START*"], ascending = False)
df = df.reset_index()
df.iloc[0,:]

#df['START*'].value_counts().head(1)
starting_point = uber_data["START*"].dropna()
df = pd.DataFrame(starting_point.value_counts())
df.sort_values(["START*"], ascending = False)
df = df.reset_index()
df = df.rename(columns = {'index':'starting_destination', 'START*':'Count'})
df.loc[df['Count'] == max(df['Count'])]

uber_data['START*'].value_counts().head(1)

"""##The **Most popular dropping point** for the Uber drivers
###dataframe with no 'na' values in the 'STOP' variable.
"""

#least popular dropping point
uber_data["STOP*"].value_counts().tail(1)

#most popular dropping point
uber_data["STOP*"].value_counts().head(1)

stopping_point = uber_data["STOP*"].dropna()
df = pd.DataFrame(stopping_point.value_counts())
df.sort_values(["STOP*"], ascending = False)

df = df.reset_index()
df = df.rename(columns = {'index':'stopping_destination', 'STOP*':'Count'})
df.loc[df['Count'] == max(df['Count'])]

"""##The most frequent route taken by Uber drivers.
###dataframe with no 'na' values.
"""

df = uber_data.dropna()
df = pd.DataFrame(df.groupby(['START*', 'STOP*']).size())
df = df.rename(columns = {0:'Count'})
df = df.sort_values(['Count'], ascending = False)
df.loc[df['Count'] == max(df['Count'])]

"""##Print all types of purposes for the trip in an array.
###dataframe with no 'na' values in the 'PURPOSE' variable.
"""

print(np.array(uber_data['PURPOSE*'].dropna().unique()))
uber_data['MILES*'].groupby(uber_data['PURPOSE*']).sum()

"""##Plot a bar graph of Purposes vs Distance.
###based on the original dataframe.
"""

df = pd.DataFrame(uber_data['MILES*'].groupby(uber_data['PURPOSE*']).sum())
df.plot(kind = 'bar')
plt.show()

#OR
df = df.reset_index()
sns.barplot(x = df['MILES*'], y = df['PURPOSE*'])

"""## Print a dataframe of Purposes and the distance travelled for that particular Purpose.
###based on the original dataframe.
"""

df

"""#Graphs

##Transforming the Data
Getting an hour, day, days of the week, a month from the date of the trip.
"""

uber_data['START_DATE*'] = pd.to_datetime(uber_data['START_DATE*'], infer_datetime_format=True, errors='coerce')
uber_data['END_DATE*'] = pd.to_datetime(uber_data['END_DATE*'], infer_datetime_format=True, errors='coerce')

# Create empty lists for hour, day, dayofweek, month, and weekday
hour, day, dayofweek, month, weekday = [], [], [], [], []

for x in uber_data['START_DATE*']:
    hour.append(x.hour)
    day.append(x.day)
    dayofweek.append(x.dayofweek if not pd.isnull(x) else None)
    month.append(x.month)
    weekday.append(calendar.day_name[int(x.dayofweek)] if not pd.isnull(x.dayofweek) else None)

# Add columns to the DataFrame
uber_data['HOUR'] = hour
uber_data['DAY'] = day
uber_data['DAY_OF_WEEK'] = dayofweek
uber_data['MONTH'] = month
uber_data['WEEKDAY'] = weekday

uber_data.head()

"""##Calculating Avg speed of the Trip"""

uber_data['TRAVELLING_TIME'] = uber_data['TRAVELLING_TIME']/60
uber_data['SPEED'] = uber_data['MILES*']/uber_data['TRAVELLING_TIME']
uber_data.head()

"""##Plot number of trips vs Category of trips."""

uber_data.head()

df = pd.DataFrame(uber_data['CATEGORY*'].value_counts())
df.reset_index()

df.plot(kind = 'bar')
plt.show()

"""##Histogram for miles. Most of people not having a long trip."""

uber_data['MILES*'].plot.hist()

"""##Trips for purpose.
###Mostly the purpose of the trip is meeting and meal/entertain.
"""

plt.figure(figsize=(15,4))
ax = sns.countplot(data=uber_data, x='PURPOSE*', hue='CATEGORY*')
ax.set_title("Trips for Purpose", fontsize=20)
plt.xlabel("PURPOSE", fontsize=17)
plt.ylabel("count", fontsize=17)
for p in ax.patches:
    ax.annotate(f'\n{p.get_height()}', (p.get_x()+0.2, p.get_height()), color='black', size=15, ha="center")

plt.show()

"""##Comparing all the purpose with miles, hour, day of the month, day of the week, month, Travelling time.

"""

uber_data.groupby('PURPOSE*').mean().plot(kind='bar', figsize=(15,5))

"""##proportion of trips that is Business and what is the proportion of trips that is Personal

1.  The proportion calculation is with respect to the 'miles' variable.
2.  This question is based on the original dataframe.



"""

import warnings

# Suppress FutureWarning
warnings.simplefilter(action='ignore', category=FutureWarning)
df = uber_data.groupby(['CATEGORY*']).sum()
df

import warnings

# Suppress FutureWarning
warnings.simplefilter(action='ignore', category=FutureWarning)
df = uber_data.groupby(['CATEGORY*']).sum()
Business = df.iloc[0,0]/(df.iloc[0,0] + df.iloc[1,0])
Personal = df.iloc[1,0]/(df.iloc[0,0] + df.iloc[1,0])
#df
print("Business:", Business)
print("Personal:", Personal)